{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91717,"databundleVersionId":12184666,"sourceType":"competition"},{"sourceId":11592231,"sourceType":"datasetVersion","datasetId":7269189}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:07.972671Z","iopub.execute_input":"2025-06-24T11:56:07.972884Z","iopub.status.idle":"2025-06-24T11:56:10.127601Z","shell.execute_reply.started":"2025-06-24T11:56:07.972866Z","shell.execute_reply":"2025-06-24T11:56:10.126586Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport random\nimport os\nimport gc\n\nimport xgboost as xgb\n\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder\n\nimport warnings\nwarnings.simplefilter('ignore')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:10.129607Z","iopub.execute_input":"2025-06-24T11:56:10.130050Z","iopub.status.idle":"2025-06-24T11:56:11.901855Z","shell.execute_reply.started":"2025-06-24T11:56:10.130027Z","shell.execute_reply":"2025-06-24T11:56:11.901020Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CFG:\n    path = \"../input/playground-series-s5e6/\"\n    original_path = \"../input/fertilizer-prediction/\"\n\n    n_splits = 10\n    n_repeats = 10\n    seed = 42\n    \n    learning_rate = 5e-2\n    num_boost_round = 10000\n    early_stopping_rounds = 100\n    verbose_eval = 500\n\n    target = \"Fertilizer Name\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:11.902799Z","iopub.execute_input":"2025-06-24T11:56:11.903161Z","iopub.status.idle":"2025-06-24T11:56:11.907923Z","shell.execute_reply.started":"2025-06-24T11:56:11.903140Z","shell.execute_reply":"2025-06-24T11:56:11.907132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n\nseed_everything()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:11.908611Z","iopub.execute_input":"2025-06-24T11:56:11.908904Z","iopub.status.idle":"2025-06-24T11:56:11.926312Z","shell.execute_reply.started":"2025-06-24T11:56:11.908875Z","shell.execute_reply":"2025-06-24T11:56:11.925283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pd.read_csv(CFG.path + \"train.csv\").drop(columns=['id'])\ntest = pd.read_csv(CFG.path + \"test.csv\").drop(columns=['id'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:11.928761Z","iopub.execute_input":"2025-06-24T11:56:11.929028Z","iopub.status.idle":"2025-06-24T11:56:13.595154Z","shell.execute_reply.started":"2025-06-24T11:56:11.929008Z","shell.execute_reply":"2025-06-24T11:56:13.594273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"original = pd.read_csv(CFG.original_path + \"Fertilizer Prediction.csv\")\noriginal_copy = original.copy()\nfor i in range(5):\n    original = pd.concat([original, original_copy], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:13.596089Z","iopub.execute_input":"2025-06-24T11:56:13.596389Z","iopub.status.idle":"2025-06-24T11:56:13.821234Z","shell.execute_reply.started":"2025-06-24T11:56:13.596359Z","shell.execute_reply":"2025-06-24T11:56:13.820312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def add_catfeatures(df, cols):\n    for col in cols:\n        df[f\"{col}_Binned\"] = df[col].astype(\"category\")\n    return df\n\nnum_cols = [col for col in test.select_dtypes(exclude=['object', 'category']).columns]\ntrain = add_catfeatures(train, num_cols)\ntest = add_catfeatures(test, num_cols)\noriginal = add_catfeatures(original, num_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:13.822075Z","iopub.execute_input":"2025-06-24T11:56:13.822330Z","iopub.status.idle":"2025-06-24T11:56:13.940373Z","shell.execute_reply.started":"2025-06-24T11:56:13.822311Z","shell.execute_reply":"2025-06-24T11:56:13.939493Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def add_catfeatures(df, cols):\n    for col in cols:\n        df[f\"{col}_Binned\"] = df[col].astype(\"category\")\n    return df\n\nnum_cols = [col for col in test.select_dtypes(exclude=['object', 'category']).columns]\ntrain = add_catfeatures(train, num_cols)\ntest = add_catfeatures(test, num_cols)\noriginal = add_catfeatures(original, num_cols)\ndef rename_temperature_column(df):\n    df = df.rename(columns={'Temparature': 'Temperature'})\n    return df\n    \ntrain = rename_temperature_column(train)\ntest = rename_temperature_column(test)\noriginal = rename_temperature_column(original)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:13.941259Z","iopub.execute_input":"2025-06-24T11:56:13.941570Z","iopub.status.idle":"2025-06-24T11:56:14.209151Z","shell.execute_reply.started":"2025-06-24T11:56:13.941541Z","shell.execute_reply":"2025-06-24T11:56:14.208276Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_cols = [col for col in test.select_dtypes(include=['object', 'category']).columns]\n\nfor col in cat_cols:\n    label_enc = LabelEncoder()\n    train[col] = label_enc.fit_transform(train[col])\n    test[col] = label_enc.transform(test[col])\n    original[col] = label_enc.transform(original[col])\n\nfor col in cat_cols:\n    train[col] = train[col].astype(\"category\")\n    test[col] = test[col].astype(\"category\")\n    original[col] = original[col].astype(\"category\")\n\ndel label_enc\ngc.collect()\ntarget_label_enc = LabelEncoder()\ntrain[CFG.target] = target_label_enc.fit_transform(train[CFG.target])\noriginal[CFG.target] = target_label_enc.transform(original[CFG.target])\nfeatures = [col for col in test.columns if col != CFG.target]\nfor col in features:\n    if train[col].nunique() == 1:\n        features.remove(col)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:14.210032Z","iopub.execute_input":"2025-06-24T11:56:14.210329Z","iopub.status.idle":"2025-06-24T11:56:16.006672Z","shell.execute_reply.started":"2025-06-24T11:56:14.210304Z","shell.execute_reply":"2025-06-24T11:56:16.005750Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train[features]\noriginal[features]\ntest[features]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:16.007453Z","iopub.execute_input":"2025-06-24T11:56:16.007742Z","iopub.status.idle":"2025-06-24T11:56:16.067881Z","shell.execute_reply.started":"2025-06-24T11:56:16.007717Z","shell.execute_reply":"2025-06-24T11:56:16.066965Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def mapk(actual, predicted, k=3):\n    def apk(a, p, k):\n        p = p[:k]\n        score = 0.0\n        hits = 0\n        seen = set()\n        for i, pred in enumerate(p):\n            if pred in a and pred not in seen:\n                hits += 1\n                score += hits / (i + 1.0)\n                seen.add(pred)\n        return score / min(len(a), k)\n    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:16.068842Z","iopub.execute_input":"2025-06-24T11:56:16.069096Z","iopub.status.idle":"2025-06-24T11:56:16.075156Z","shell.execute_reply.started":"2025-06-24T11:56:16.069076Z","shell.execute_reply":"2025-06-24T11:56:16.074208Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# XGBoost parameters\nparams = {\n    'objective': 'multi:softprob',\n    'num_class': train[CFG.target].nunique(),\n    'seed': CFG.seed,\n    'max_depth': 8,\n    'max_bins': 128,\n    'learning_rate': CFG.learning_rate,\n    'min_child_weight': 2,\n    'alpha': 6.5,\n    'reg_lambda': 5.3,\n    'subsample': 0.8,\n    'colsample_bytree': 0.3,\n    'tree_method': 'hist',  \n    'device': \"cuda\"\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:16.076116Z","iopub.execute_input":"2025-06-24T11:56:16.076403Z","iopub.status.idle":"2025-06-24T11:56:16.102012Z","shell.execute_reply.started":"2025-06-24T11:56:16.076381Z","shell.execute_reply":"2025-06-24T11:56:16.100998Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport ipywidgets as widgets\nfrom IPython.display import display, Image\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:16.103006Z","iopub.execute_input":"2025-06-24T11:56:16.103315Z","iopub.status.idle":"2025-06-24T11:56:16.768484Z","shell.execute_reply.started":"2025-06-24T11:56:16.103292Z","shell.execute_reply":"2025-06-24T11:56:16.767656Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/playground-series-s5e6/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/playground-series-s5e6/test.csv\")\noriginal = pd.read_csv(\"/kaggle/input/fertilizer-prediction/Fertilizer Prediction.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:16.771945Z","iopub.execute_input":"2025-06-24T11:56:16.772337Z","iopub.status.idle":"2025-06-24T11:56:17.692323Z","shell.execute_reply.started":"2025-06-24T11:56:16.772314Z","shell.execute_reply":"2025-06-24T11:56:17.691444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:17.693159Z","iopub.execute_input":"2025-06-24T11:56:17.693475Z","iopub.status.idle":"2025-06-24T11:56:17.704624Z","shell.execute_reply.started":"2025-06-24T11:56:17.693448Z","shell.execute_reply":"2025-06-24T11:56:17.703799Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:17.705612Z","iopub.execute_input":"2025-06-24T11:56:17.706001Z","iopub.status.idle":"2025-06-24T11:56:17.857971Z","shell.execute_reply.started":"2025-06-24T11:56:17.705981Z","shell.execute_reply":"2025-06-24T11:56:17.857075Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:17.858833Z","iopub.execute_input":"2025-06-24T11:56:17.859127Z","iopub.status.idle":"2025-06-24T11:56:17.898070Z","shell.execute_reply.started":"2025-06-24T11:56:17.859101Z","shell.execute_reply":"2025-06-24T11:56:17.897127Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"original.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:17.899023Z","iopub.execute_input":"2025-06-24T11:56:17.899338Z","iopub.status.idle":"2025-06-24T11:56:17.929802Z","shell.execute_reply.started":"2025-06-24T11:56:17.899313Z","shell.execute_reply":"2025-06-24T11:56:17.928590Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add 'source' label\n#original['Source'] = 'real'\n#train['Source'] = 'synth'\n\n# Drop the 'id' column\nX = train.drop(columns=['id', 'Fertilizer Name'])\n\n# Extract the target column\ny = train['Fertilizer Name']\n\nX.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:17.930713Z","iopub.execute_input":"2025-06-24T11:56:17.931039Z","iopub.status.idle":"2025-06-24T11:56:17.966132Z","shell.execute_reply.started":"2025-06-24T11:56:17.931014Z","shell.execute_reply":"2025-06-24T11:56:17.965379Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"le = LabelEncoder()\ny_encoded = le.fit_transform(y)\n\n# Output labels are now numbers\ny_encoded[:10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:17.967018Z","iopub.execute_input":"2025-06-24T11:56:17.967334Z","iopub.status.idle":"2025-06-24T11:56:18.127122Z","shell.execute_reply.started":"2025-06-24T11:56:17.967295Z","shell.execute_reply":"2025-06-24T11:56:18.126283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Just check\nX.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:18.128087Z","iopub.execute_input":"2025-06-24T11:56:18.128475Z","iopub.status.idle":"2025-06-24T11:56:18.235781Z","shell.execute_reply.started":"2025-06-24T11:56:18.128447Z","shell.execute_reply":"2025-06-24T11:56:18.234831Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare multiple copies of original dataset\norig_copy = original.copy()\n\n# Number of copies\nn = 6\nfor i in range(n):\n    original = pd.concat([original, orig_copy], axis=0, ignore_index=True)\n    \noriginal.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:18.236909Z","iopub.execute_input":"2025-06-24T11:56:18.237314Z","iopub.status.idle":"2025-06-24T11:56:18.434157Z","shell.execute_reply.started":"2025-06-24T11:56:18.237286Z","shell.execute_reply":"2025-06-24T11:56:18.433248Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Identify underrepresented classes\ntrain['Fertilizer Name'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:18.435042Z","iopub.execute_input":"2025-06-24T11:56:18.435338Z","iopub.status.idle":"2025-06-24T11:56:18.498114Z","shell.execute_reply.started":"2025-06-24T11:56:18.435311Z","shell.execute_reply":"2025-06-24T11:56:18.497201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Identify underrepresented classes\norig_copy['Fertilizer Name'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:18.498921Z","iopub.execute_input":"2025-06-24T11:56:18.499192Z","iopub.status.idle":"2025-06-24T11:56:18.528599Z","shell.execute_reply.started":"2025-06-24T11:56:18.499174Z","shell.execute_reply":"2025-06-24T11:56:18.527660Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Store scores\nf1_scores = []\nmap3_scores = []\nmodels = []\n\n# Collect predictions and true labels across all folds\nall_y_true = []\nall_y_pred = []\n\n# Prepare K-Fold\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X, y_encoded)):\n    print(f\"\\n***** Fold {fold + 1} *****\")\n\n    # Make full copies to avoid warnings\n    X_train = X.iloc[train_idx].copy()\n    X_val = X.iloc[val_idx].copy()\n    y_train = y_encoded[train_idx]\n    y_val = y_encoded[val_idx]\n\n    # Combine original with train data \n    X_train = pd.concat([X_train, original], ignore_index=True)\n    y_train = np.concatenate([y_train, le.transform(original['Fertilizer Name'])])\n\n    # Drop target column from training data\n    X_train.drop(columns=['Fertilizer Name'], inplace=True)\n\n    # Convert all features to categorical (except target, which is already separated)\n    for col in X_train.columns:\n        X_train[col] = X_train[col].astype('category')\n        \n    for col in X_val.columns:\n        X_val[col] = X_val[col].astype('category')\n    \n    cat_features = X_train.columns.tolist()   # capture all input columns\n\n    # For debugging purposes\n    # print(cat_features)\n    # print(X_train.info())\n    # print(X_val.info())\n\n    model = XGBClassifier(\n                max_depth=7,\n                colsample_bytree=0.4,\n                subsample=0.8,\n                n_estimators=10000,\n                learning_rate=0.01,\n                gamma=0.26,\n                max_delta_step=4,\n                reg_alpha=2.7,\n                reg_lambda=1.4,\n                objective='multi:softprob',\n                random_state=13,\n                enable_categorical=True,\n                tree_method='hist',     \n                device='cuda'  \n            )\n\n    model.fit(\n        X_train,\n        y_train,\n        eval_set=[(X_train, y_train),(X_val, y_val)],\n        early_stopping_rounds=50,\n        verbose=500,\n    )\n    \n    # Predict class labels and probabilities\n    y_pred = model.predict(X_val)\n    y_probs = model.predict_proba(X_val)\n\n    # Store predictions and true labels\n    all_y_true.extend(y_val)\n    all_y_pred.extend(y_pred)\n\n    # F1 Score\n    report = classification_report(y_val, y_pred, output_dict=True)\n    f1_macro = report[\"macro avg\"][\"f1-score\"]\n    f1_scores.append(f1_macro)\n    \n    # MAP@3\n    top3_preds = np.argsort(y_probs, axis=1)[:, -3:][:, ::-1]\n    \n    def mapk(actual, predicted, k=3):\n        def apk(a, p, k):\n            if a in p[:k]:\n                return 1.0 / (p[:k].index(a) + 1)\n            return 0.0\n        return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])\n\n    map3 = mapk(y_val.tolist(), top3_preds.tolist(), k=3)\n    map3_scores.append(map3)\n    models.append(model)\n\n    print(f\"F1 (macro): {f1_macro:.4f} | MAP@3: {map3:.4f}\")\n\n# Final Results\nprint(\"\\n***** Final CV Results *****\")\nprint(f\"Avg F1: {np.mean(f1_scores):.4f}\")\nprint(f\"Avg MAP@3: {np.mean(map3_scores):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-24T11:56:18.529480Z","iopub.execute_input":"2025-06-24T11:56:18.529724Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Loss curves for the last fold\nresults = model.evals_result()\nplt.plot(results['validation_0']['mlogloss'], label='Train')\nplt.plot(results['validation_1']['mlogloss'], label='Val')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Confusion matrix\ncm = confusion_matrix(all_y_true, all_y_pred)\ncm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n# Step 2: Make it pretty\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm_norm, annot=True, fmt=\".3f\", cmap=\"Greens\", \n            xticklabels=le.classes_, yticklabels=le.classes_,\n           )\n\nplt.title(\"Normalized Confusion Matrix\", fontsize=16)\nplt.xlabel(\"Predicted Label\", fontsize=12)\nplt.ylabel(\"True Label\", fontsize=12)\nplt.xticks(rotation=0)\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_val, y_pred, digits=4))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize accumulator\nimportances_total = np.zeros(len(cat_features))\nfeature_names = cat_features\n\n# Accumulate importance per model\nfor model in models:\n    importances_total += model.feature_importances_\n\n# Average\nimportances_avg = importances_total / len(models)\n\n# Make a dataframe\nimportances_df = pd.DataFrame({\n    'feature': feature_names,\n    'importance': importances_avg\n}).sort_values(by='importance', ascending=False)\n# Limit to top N features for readability, default to all columns\ntop_n = len(X_train.columns)\ntop_features = importances_df.head(top_n)\n\n# Create a green color palette\ngreen_palette = sns.color_palette(\"Greens\", as_cmap=False, n_colors=len(top_features))\n\n# Plot using barplot\nplt.figure(figsize=(8, 5))\n\nsns.barplot(\n    data=top_features,\n    y='feature',\n    x='importance',\n    palette=green_palette\n)\n\nplt.title(\"Top Feature Importances\")\nplt.grid(axis='x', linestyle='--', alpha=0.6)\nplt.xlabel(\"Importance\")\nplt.ylabel(\"Feature\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# y_true should be integer labels (encoded)\n# y_proba is shape (n_samples, n_classes)\nn_classes = y_probs.shape[1]\n\n# Initialize matrix\nsoft_cm = np.zeros((n_classes, n_classes))\n\n# Fill it\nfor i in range(len(y_val)):\n    true_class = y_val[i]\n    soft_cm[true_class] += y_probs[i]  # adds vector of predicted probs\n\n# Normalize each row (optional)\nsoft_cm_normalized = soft_cm / soft_cm.sum(axis=1, keepdims=True)\n\n# Plot it!\nplt.figure(figsize=(8, 6))\nsns.heatmap(soft_cm_normalized, annot=True, fmt=\".3f\", cmap=\"Greens\",\n            xticklabels=le.classes_, yticklabels=le.classes_)\nplt.xlabel(\"Predicted Class\", fontsize=12)\nplt.ylabel(\"True Class\", fontsize=12)\nplt.title(\"Soft Confusion Matrix (Probabilities)\", fontsize=16)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def top_n_coverage(y_true, y_proba, n=3):\n    \"\"\"Returns the proportion of times the true label is in the top-N predicted labels.\"\"\"\n    top_n_preds = np.argsort(y_proba, axis=1)[:, -n:]  # Get top N indices (classes)\n    \n    # Check if the true label is in the top N predictions\n    hits = [y_true[i] in top_n_preds[i] for i in range(len(y_true))]\n    \n    return np.mean(hits)\n\nfor n in range(1, 8):\n    coverage = top_n_coverage(y_val, y_probs, n)\n    print(f\"Top-{n} Coverage: {coverage:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Setup: Top-N values\ntop_ns = list(range(1, y_probs.shape[1] + 1))\ncoverages = [top_n_coverage(y_val, y_probs, n) for n in top_ns]\n\n# Apply Seaborn theme\nsns.set(style=\"whitegrid\")\nsns.set_palette(\"Greens\")\n\n# Create figure\nplt.figure(figsize=(8, 5))\n\n# Plot with seaborn line aesthetics\nsns.lineplot(x=top_ns, y=coverages, marker='o', color='green', linewidth=2)\n\n# Decorations\nplt.title(\"Top-N Coverage Curve\", fontsize=16)\nplt.xlabel(\"N (Top-N Predictions)\", fontsize=12)\nplt.ylabel(\"Coverage\", fontsize=12)\nplt.ylim(0, 1.05)\nplt.xticks(top_ns)\nplt.yticks([i/10 for i in range(11)])\nplt.grid(True, linestyle='--', alpha=0.6)\nplt.axvline(x=3, color='red', linestyle='--', linewidth=2, label='Top-3 Threshold')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert test data\nfor col in cat_features:\n    test[col] = test[col].astype('category')\n\n# Accumulate prediction probabilities\nall_preds = np.zeros((test.shape[0], len(le.classes_)))\n\nX_test = test.drop(columns='id')\ncat_features = X_test.columns.tolist()   # capture all input columns\n\nfor model in models:\n    probs = model.predict_proba(X_test)\n    all_preds += probs\n\n# Average over folds\navg_preds = all_preds / len(models)\n\n# Get top 3 indices like before\ntop3_preds = np.argsort(probs, axis=1)[:, -3:][:, ::-1]  # Top 3 class indices, descending order\n\n# Convert class indices back to original label strings\ntop3_labels = le.inverse_transform(top3_preds.ravel()).reshape(top3_preds.shape)\n\nsubmission = pd.DataFrame({\n    'id': test['id'],  # Replace with actual ID column name\n    'Fertilizer Name': [' '.join(row) for row in top3_labels]\n})\n\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Done!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}